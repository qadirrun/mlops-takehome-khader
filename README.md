# ðŸš€ Iris Classifier - Production ML Pipeline

[![CI](https://github.com/qadirrun/mlops-takehome-khader/actions/workflows/ci.yml/badge.svg)](https://github.com/qadirrun/mlops-takehome-khader/actions/workflows/ci.yml)
[![Deploy Dev](https://github.com/qadirrun/mlops-takehome-khader/actions/workflows/deploy-dev.yml/badge.svg)](https://github.com/qadirrun/mlops-takehome-khader/actions/workflows/deploy-dev.yml)
[![Promote Prod](https://github.com/qadirrun/mlops-takehome-khader/actions/workflows/promote-prod.yml/badge.svg)](https://github.com/qadirrun/mlops-takehome-khader/actions/workflows/promote-prod.yml)
[![Python 3.12](https://img.shields.io/badge/python-3.12-blue.svg)](https://www.python.org/downloads/release/python-3120/)
[![MLflow](https://img.shields.io/badge/MLflow-3.6.0-blue.svg)](https://mlflow.org/)
[![Kubernetes](https://img.shields.io/badge/Kubernetes-Ready-blue.svg)](https://kubernetes.io/)
[![Tests](https://img.shields.io/badge/Tests-23%2F23%20Passing-brightgreen.svg)]()

A complete, production-ready ML pipeline with **FastAPI serving**, **Kubernetes orchestration**, **GitHub Actions CI/CD**, **Prometheus monitoring**, and **automated rollback procedures**.

## ðŸŽ¯ Overview

**Complete End-to-End Flow:**
```
GitHub Push â†’ CI Pipeline â†’ Train Models â†’ Build Docker â†’ Deploy Dev â†’ Manual Prod Canary â†’ Full Rollout
                                                                                    â†“
                                                                        Prometheus Monitoring
                                                                        Grafana Dashboards
                                                                        Alert Rules
```

**Key Components:**
- âœ… **FastAPI Service** - 3 replicas with health checks
- âœ… **MLflow Pipeline** - Fetch â†’ Train (3 models) â†’ Register â†’ Deploy
- âœ… **Kubernetes** - NGINX Ingress, HPA, RBAC, Blue-Green/Canary deployments
- âœ… **GitHub Actions** - CI/CD with auto dev deploy + manual prod canary
- âœ… **Monitoring** - Prometheus + Grafana + 6 alert rules
- âœ… **Rollback** - 5 strategies with copy-paste commands

## ðŸ“ Project Structure

```
mlflow/
â”œâ”€â”€ app/                              # FastAPI Service
â”‚   â”œâ”€â”€ api.py                       # FastAPI endpoints (6 endpoints)
â”‚   â”œâ”€â”€ database.py                  # PostgreSQL logging module
â”‚   â”œâ”€â”€ metrics.py                   # Prometheus metrics
â”‚   â””â”€â”€ deploy.py                    # Model serving
â”‚
â”œâ”€â”€ train/                           # Training Pipeline
â”‚   â”œâ”€â”€ data_fetch.py               # Iris dataset (150 samples)
â”‚   â”œâ”€â”€ multi_model_train.py        # Train 3 models (LR, RF, SVM)
â”‚   â”œâ”€â”€ evaluate.py                 # Evaluation metrics
â”‚   â”œâ”€â”€ register.py                 # MLflow Model Registry
â”‚   â””â”€â”€ main_loop_models.py         # Orchestrator
â”‚
â”œâ”€â”€ k8s/                            # Kubernetes Manifests
â”‚   â”œâ”€â”€ namespace.yaml              # Namespace + RBAC
â”‚   â”œâ”€â”€ deployment.yaml             # 3 replicas, RollingUpdate
â”‚   â”œâ”€â”€ service.yaml                # ClusterIP + HPA (2-10 pods)
â”‚   â”œâ”€â”€ ingress.yaml                # NGINX, TLS, rate limiting
â”‚   â”œâ”€â”€ blue-green.yaml             # Blue-Green deployment
â”‚   â”œâ”€â”€ canary.yaml                 # Canary deployment
â”‚   â””â”€â”€ deploy.sh                   # Deployment script
â”‚
â”œâ”€â”€ deploy/                         # Monitoring Configs
â”‚   â”œâ”€â”€ prometheus.yml              # Scrape config (5s interval)
â”‚   â”œâ”€â”€ alert_rules.yml             # 6 alert rules
â”‚   â”œâ”€â”€ alertmanager.yml            # Alert routing
â”‚   â”œâ”€â”€ grafana-datasources.yml     # Prometheus datasource
â”‚   â””â”€â”€ grafana-dashboards.yml      # Dashboard provisioning
â”‚
â”œâ”€â”€ dashboards/                     # Grafana Dashboards
â”‚   â”œâ”€â”€ iris-classifier-dashboard.json
â”‚   â””â”€â”€ iris-classifier-monitoring-dashboard.json
â”‚
â”œâ”€â”€ tests/                          # Unit Tests (23/23 passing)
â”‚   â”œâ”€â”€ test_api.py                # API tests
â”‚   â””â”€â”€ test_train.py              # Training tests
â”‚
â”œâ”€â”€ .github/workflows/              # GitHub Actions CI/CD
â”‚   â”œâ”€â”€ ci.yml                      # Lint â†’ Test â†’ Train â†’ Build
â”‚   â”œâ”€â”€ deploy-dev.yml              # Auto dev deploy
â”‚   â””â”€â”€ promote-prod.yml            # Manual prod canary
â”‚
â”œâ”€â”€ data/                           # Training/test data
â”œâ”€â”€ artifacts/                      # Model artifacts
â”œâ”€â”€ mlruns/                         # MLflow tracking
â”œâ”€â”€ docker-compose.yml              # Local dev stack (with PostgreSQL)
â”œâ”€â”€ Dockerfile                      # Container image
â”œâ”€â”€ requirements.txt                # Dependencies
â”œâ”€â”€ pytest.ini                      # Test config
â”œâ”€â”€ MODEL_CARD.md                   # Model documentation
â”œâ”€â”€ K8S_SUMMARY.md                  # Kubernetes overview
â”œâ”€â”€ K8S_ROLLBACK_GUIDE.md           # Rollback procedures
â””â”€â”€ README.md                       # This file
```

---

## ðŸƒ Quick Start

### Local Development (Docker Compose)

**1. Install Dependencies**
```bash
pip install -r requirements.txt
```

**2. Start Local Stack**
```bash
docker-compose up -d
```
This starts:
- FastAPI service on http://localhost:8000
- PostgreSQL database on localhost:5432 (for prediction logging)
- Prometheus on http://localhost:9090
- Grafana on http://localhost:3000 (admin/admin)
- AlertManager on http://localhost:9093

**3. Run Training Pipeline (Inside Container)**
```bash
# Wait for API to be ready (~10 seconds)
docker exec iris-classifier-api python /app/train/main_loop_models.py
```

**4. Test API**
```bash
# Health check
curl http://localhost:8000/healthz

# Single prediction
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"features": [5.1, 3.5, 1.4, 0.2]}'

# View prediction logs (stored in PostgreSQL)
curl http://localhost:8000/logs

# View metrics
curl http://localhost:8000/metrics-prometheus
```

**5. View Dashboards**
- MLflow UI: http://localhost:5000
- Grafana: http://localhost:3000
- Prometheus: http://localhost:9090

**6. Stop Stack**
```bash
docker-compose down
```

---

## ðŸ“ PostgreSQL Prediction Logging

### Overview

All predictions are automatically logged to PostgreSQL with the following information:
- **request_id** - Unique UUID for each prediction request
- **model_name** - Name of the model used (e.g., "demo-iris-LR")
- **model_version** - Version of the model (e.g., "1.0.0")
- **features** - Input features used for prediction
- **prediction** - Model output (class prediction)
- **probability** - Confidence score of the prediction
- **latency_ms** - Inference latency in milliseconds
- **timestamp** - When the prediction was made

### Database Schema

```sql
CREATE TABLE predictions (
    id SERIAL PRIMARY KEY,
    request_id VARCHAR(255) UNIQUE NOT NULL,
    model_name VARCHAR(255) NOT NULL,
    model_version VARCHAR(50) NOT NULL,
    features FLOAT8[] NOT NULL,
    prediction INTEGER NOT NULL,
    probability FLOAT NOT NULL,
    latency_ms FLOAT NOT NULL,
    timestamp TIMESTAMP NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### API Endpoints

**Get Prediction Logs:**
```bash
# Get last 100 predictions
curl http://localhost:8000/logs

# Get last 50 predictions
curl http://localhost:8000/logs?limit=50
```

**Response Example:**
```json
{
  "count": 3,
  "logs": [
    {
      "id": 1,
      "request_id": "db7f122e-096a-4ed6-9af5-610af0f4ceb4",
      "model_name": "demo-iris-LR",
      "model_version": "1.0.0",
      "features": "5.1 3.5 1.4 0.2",
      "prediction": 0,
      "probability": 0.9766,
      "latency_ms": 5.61,
      "timestamp": "2025-11-13T05:16:47.758779",
      "created_at": "2025-11-13T05:16:47.770680"
    }
  ]
}
```

### Query Logs Directly

```bash
# Connect to PostgreSQL
docker exec -it postgres-db psql -U mlflow_user -d iris_logs

# View all predictions
SELECT * FROM predictions;

# Get average latency
SELECT AVG(latency_ms) as avg_latency FROM predictions;

# Get prediction distribution
SELECT prediction, COUNT(*) as count FROM predictions GROUP BY prediction;

# Get predictions for a specific model version
SELECT * FROM predictions WHERE model_version = '1.0.0';
```

---

## ðŸ”„ CI/CD Pipeline Explanation

### GitHub Actions Workflows

#### 1. **CI Pipeline** (`.github/workflows/ci.yml`)
**Trigger:** Push to main/develop, Pull Requests

**Steps:**
```
1. Lint Code (Flake8, Pylint)
   â†“
2. Run Unit Tests (23/23 passing)
   â†“
3. Train Models (3 models: LR, RF, SVM)
   â†“
4. Build Docker Image
   â†“
5. Upload Artifacts
```

**Commands:**
```bash
# Manually trigger CI
git push origin main
```

#### 2. **Auto Dev Deploy** (`.github/workflows/deploy-dev.yml`)
**Trigger:** Automatic on push to main

**Steps:**
```
1. Deploy to dev environment
   â†“
2. Run smoke tests (healthz, predict)
   â†“
3. Send Slack notification
```

**Result:** Dev environment always has latest code

#### 3. **Manual Prod Canary Rollout** (`.github/workflows/promote-prod.yml`)
**Trigger:** Manual workflow dispatch

**Job 1: Canary Deployment (10% traffic)**
```
1. Deploy canary version
2. Run smoke tests
3. Monitor for 5 minutes
4. Check error rates & latency
```

**Job 2: Full Production Promotion (100% traffic)**
```
1. Deploy to 100% traffic
2. Run smoke tests
3. Create GitHub release
4. Send Slack notification
```

**How to Trigger:**
```
1. Go to GitHub Actions
2. Select "Promote to Production"
3. Click "Run workflow"
4. Monitor canary metrics
5. Approve full rollout
```

---

## ðŸ”„ Orchestration & Pipeline Steps

### Training Pipeline Flow

**File:** `train/main_loop_models.py`

```
1. Data Fetch (train/data_fetch.py)
   â””â”€ Load Iris dataset (150 samples, 4 features, 3 classes)
   â””â”€ Split: 80% train (120) / 20% test (30)
   â””â”€ Output: X_train, X_test, y_train, y_test

2. Train 3 Models in Loop
   â”œâ”€ Model 1: Logistic Regression
   â”‚  â””â”€ MLflow: Log params, metrics, model
   â”œâ”€ Model 2: Random Forest (100 trees)
   â”‚  â””â”€ MLflow: Log params, metrics, feature importance
   â””â”€ Model 3: Support Vector Machine
      â””â”€ MLflow: Log params, metrics, model

3. Evaluate Each Model (train/evaluate.py)
   â””â”€ Calculate: Accuracy, Precision, Recall, F1-score
   â””â”€ Generate: Classification report, Confusion matrix
   â””â”€ Log artifacts to MLflow

4. Select Best Model
   â””â”€ Compare F1-scores across all models
   â””â”€ Choose highest performing model

5. Register in MLflow (train/register.py)
   â””â”€ Register to MLflow Model Registry
   â””â”€ Transition to "Production" stage
   â””â”€ Track version history

6. Deploy
   â””â”€ FastAPI loads model from registry
   â””â”€ Serve predictions via HTTP
```

**Important:** Training must run **inside the Docker container** to ensure MLflow stores artifact paths correctly for container environments.

**Run Training Inside Container:**
```bash
# Start the stack first
docker-compose up -d

# Wait for API to be ready (~10 seconds)
sleep 10

# Run training inside container
docker exec iris-classifier-api python /app/train/main_loop_models.py
```

**View Results:**
```bash
mlflow ui
# Open http://localhost:5000
```

---

## â˜¸ï¸ Kubernetes Deployment & Load Balancing

### Architecture

```
Internet
   â†“
DNS (iris-classifier.example.com)
   â†“
NGINX Ingress (TLS, Rate Limit: 100 req/min, 10 RPS)
   â†“
Service (ClusterIP - Round-robin load balancing)
   â†“
3 Pods (Replicas)
â”œâ”€ Pod 1: iris-classifier:latest
â”œâ”€ Pod 2: iris-classifier:latest
â””â”€ Pod 3: iris-classifier:latest
   â†“
Auto-Scaling (HPA: 2-10 pods based on CPU/Memory)
```

### Setup Instructions

**1. Create Namespace & RBAC**
```bash
kubectl apply -f k8s/namespace.yaml
```

**2. Deploy Application**
```bash
kubectl apply -f k8s/deployment.yaml
kubectl apply -f k8s/service.yaml
kubectl apply -f k8s/ingress.yaml
```

**3. Verify Deployment**
```bash
# Check pods
kubectl get pods -n iris-classifier

# Check service
kubectl get svc -n iris-classifier

# Check ingress
kubectl get ingress -n iris-classifier

# View logs
kubectl logs -n iris-classifier -l app=iris-classifier -f
```

### Load Balancing Details

**Service Configuration** (`k8s/service.yaml`):
- **Type:** ClusterIP (round-robin by default)
- **Port:** 80 â†’ 8000
- **Load Balancing:** Automatic round-robin across 3 replicas

**Ingress Configuration** (`k8s/ingress.yaml`):
- **Controller:** NGINX
- **TLS/SSL:** Let's Encrypt (cert-manager)
- **Rate Limiting:** 100 requests/min, 10 RPS
- **CORS:** Enabled
- **Domain:** iris-classifier.example.com

**Health Checks:**
```yaml
Startup Probe:    failureThreshold: 30, periodSeconds: 10
Readiness Probe:  periodSeconds: 10, timeoutSeconds: 5
Liveness Probe:   periodSeconds: 10, timeoutSeconds: 5
```

### Deployment Strategies

#### Rolling Update (Default)
```bash
# Deploy with rolling update
kubectl apply -f k8s/deployment.yaml

# Monitor rollout
kubectl rollout status deployment/iris-classifier -n iris-classifier

# View rollout history
kubectl rollout history deployment/iris-classifier -n iris-classifier
```

#### Blue-Green Deployment
```bash
# Deploy blue-green
kubectl apply -f k8s/blue-green.yaml

# Switch traffic from blue to green
kubectl patch service iris-classifier -n iris-classifier \
  -p '{"spec":{"selector":{"version":"green"}}}'
```

#### Canary Deployment
```bash
# Deploy canary (10% traffic)
kubectl apply -f k8s/canary.yaml

# Monitor canary metrics
kubectl get pods -n iris-classifier -l version=canary

# Promote canary to stable
kubectl patch service iris-classifier -n iris-classifier \
  -p '{"spec":{"selector":{"version":"stable"}}}'
```

### Auto-Scaling (HPA)

**Configuration:**
- Min Pods: 2
- Max Pods: 10
- Target CPU: 70%
- Target Memory: 80%

**View HPA Status:**
```bash
kubectl get hpa -n iris-classifier

kubectl describe hpa iris-classifier -n iris-classifier
```

**Manual Scaling:**
```bash
# Scale to 5 replicas
kubectl scale deployment iris-classifier --replicas=5 -n iris-classifier

# View current replicas
kubectl get deployment iris-classifier -n iris-classifier
```

---

## ðŸ”Œ API Endpoints

### Available Endpoints

| Endpoint | Method | Description | Response |
|----------|--------|-------------|----------|
| `/healthz` | GET | Health check | `{"status": "ok"}` |
| `/info` | GET | Model info | `{"model_name": "demo-iris-LR", "version": "1.0.0", ...}` |
| `/predict` | POST | Make prediction | `{"prediction": 0, "probability": 0.98, "latency_ms": 5.6, ...}` |
| `/metrics-prometheus` | GET | Prometheus metrics | Prometheus format |
| `/logs` | GET | Get prediction logs | `{"count": 3, "logs": [...]}` |

### Endpoint Details

**1. Health Check**
```bash
curl http://localhost:8000/healthz
```
Response:
```json
{"status": "ok"}
```

**2. Model Info**
```bash
curl http://localhost:8000/info
```
Response:
```json
{
  "model_name": "demo-iris-LR",
  "version": "1.0.0",
  "environment": "dev",
  "canary_percentage": 100
}
```

**3. Make Prediction**
```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"features": [5.1, 3.5, 1.4, 0.2]}'
```
Response:
```json
{
  "prediction": 0,
  "probability": 0.9766,
  "latency_ms": 5.61,
  "model": "demo-iris-LR",
  "version": "1.0.0",
  "request_id": "db7f122e-096a-4ed6-9af5-610af0f4ceb4"
}
```

**4. Prometheus Metrics**
```bash
curl http://localhost:8000/metrics-prometheus
```
Returns metrics in Prometheus format for scraping.

**5. Get Prediction Logs**
```bash
# Get last 100 predictions
curl http://localhost:8000/logs

# Get last 50 predictions
curl http://localhost:8000/logs?limit=50
```
Response:
```json
{
  "count": 3,
  "logs": [
    {
      "id": 1,
      "request_id": "db7f122e-096a-4ed6-9af5-610af0f4ceb4",
      "model_name": "demo-iris-LR",
      "model_version": "1.0.0",
      "features": "5.1 3.5 1.4 0.2",
      "prediction": 0,
      "probability": 0.9766,
      "latency_ms": 5.61,
      "timestamp": "2025-11-13T05:16:47.758779",
      "created_at": "2025-11-13T05:16:47.770680"
    }
  ]
}
```

---

## ðŸ“Š Monitoring & Alerts

### Prometheus Metrics

**Scrape Configuration:**
- **Interval:** 5 seconds
- **Target:** iris-classifier-api:8000/metrics-prometheus
- **Config File:** `deploy/prometheus.yml`

**Metrics Collected (9 total):**

| Metric | Type | Description |
|--------|------|-------------|
| `iris_requests_total` | Counter | Total HTTP requests |
| `iris_request_latency_seconds` | Histogram | Request latency (P50, P95, P99) |
| `iris_predictions_total` | Counter | Total predictions made |
| `iris_prediction_latency_seconds` | Histogram | Prediction latency |
| `iris_errors_total` | Counter | Total errors |
| `iris_rps` | Gauge | Requests per second |
| `iris_cpu_usage_percent` | Gauge | CPU usage % |
| `iris_memory_usage_mb` | Gauge | Memory usage MB |
| `iris_model_loaded` | Gauge | Model load status (1=loaded, 0=failed) |

**Query Examples:**
```promql
# Request rate (RPS)
rate(iris_requests_total[1m])

# P95 latency
histogram_quantile(0.95, iris_request_latency_seconds_bucket)

# Error rate
rate(iris_errors_total[5m]) / rate(iris_requests_total[5m])

# CPU usage
iris_cpu_usage_percent

# Model status
iris_model_loaded
```

### Grafana Dashboards

**Dashboard 1: iris-classifier-dashboard.json**
- Request metrics (count, rate, latency)
- Prediction metrics (count, latency)
- Error rates and trends

**Dashboard 2: iris-classifier-monitoring-dashboard.json**
- System metrics (CPU, Memory)
- Model status
- Alert status

**Access:**
```
http://localhost:3000
Username: admin
Password: admin
```

### Alert Rules (6 Total)

**File:** `deploy/alert_rules.yml`

| Alert | Condition | Duration | Action |
|-------|-----------|----------|--------|
| **HighErrorRate** | Error rate > 5% | 5 minutes | Page on-call |
| **HighLatency** | P95 latency > 1.0s | 5 minutes | Page on-call |
| **HighCPUUsage** | CPU > 80% | 5 minutes | Alert |
| **HighMemoryUsage** | Memory > 85% | 5 minutes | Alert |
| **ModelNotLoaded** | Model status = 0 | 1 minute | Critical alert |
| **LowRPS** | RPS < 0.1 | 10 minutes | Warning |

**View Alerts:**
```bash
# Prometheus alerts
curl http://localhost:9090/api/v1/alerts

# AlertManager
curl http://localhost:9093/api/v1/alerts
```

### Alert Routing

**File:** `deploy/alertmanager.yml`

**Notification Channels:**
- Email (configure SMTP)
- Slack (configure webhook)
- PagerDuty (configure integration key)

**Configure Slack Notifications:**
```yaml
# deploy/alertmanager.yml
slack_configs:
  - api_url: 'YOUR_SLACK_WEBHOOK_URL'
    channel: '#alerts'
    title: 'Iris Classifier Alert'
```

### Testing Alerts

**Generate High Error Rate:**
```bash
# Send invalid requests to trigger errors
for i in {1..100}; do
  curl -X POST http://localhost:8000/predict \
    -H "Content-Type: application/json" \
    -d '{"invalid": "data"}'
done
```

**Check Alert Status:**
```bash
# View firing alerts
curl http://localhost:9090/api/v1/alerts?state=firing

# View alert history
# Go to Prometheus UI: http://localhost:9090/alerts
```

---

## ï¿½ Rollback Procedures

### 5 Rollback Strategies

#### 1. **Rolling Update Rollback** (Default)
**When to use:** Standard deployments with RollingUpdate strategy

**Rollback command:**
```bash
# Undo last deployment
kubectl rollout undo deployment/iris-classifier -n iris-classifier

# Undo to specific revision
kubectl rollout history deployment/iris-classifier -n iris-classifier
kubectl rollout undo deployment/iris-classifier --to-revision=2 -n iris-classifier

# Monitor rollback
kubectl rollout status deployment/iris-classifier -n iris-classifier
```

**Verify:**
```bash
# Check current version
kubectl get deployment iris-classifier -n iris-classifier -o jsonpath='{.spec.template.spec.containers[0].image}'

# Check pod status
kubectl get pods -n iris-classifier
```

#### 2. **Blue-Green Rollback**
**When to use:** Zero-downtime deployments with instant traffic switch

**Rollback command:**
```bash
# Switch traffic back to blue
kubectl patch service iris-classifier -n iris-classifier \
  -p '{"spec":{"selector":{"version":"blue"}}}'

# Verify traffic switched
kubectl get service iris-classifier -n iris-classifier -o jsonpath='{.spec.selector}'

# Delete green deployment
kubectl delete deployment iris-classifier-green -n iris-classifier
```

**Verify:**
```bash
# Check service selector
kubectl get svc iris-classifier -n iris-classifier -o yaml | grep -A 5 selector

# Test endpoint
curl http://iris-classifier.example.com/healthz
```

#### 3. **Canary Rollback**
**When to use:** Canary deployments with gradual traffic shift

**Rollback command:**
```bash
# Delete canary deployment
kubectl delete deployment iris-classifier-canary -n iris-classifier

# Verify canary removed
kubectl get pods -n iris-classifier -l version=canary

# Confirm traffic on stable
kubectl get service iris-classifier -n iris-classifier -o jsonpath='{.spec.selector}'
```

**Verify:**
```bash
# Check no canary pods
kubectl get pods -n iris-classifier | grep canary

# Monitor metrics
curl http://localhost:9090/api/v1/query?query=iris_requests_total
```

#### 4. **Helm Rollback** (If using Helm)
**When to use:** Helm-managed deployments

**Rollback command:**
```bash
# View release history
helm history iris-classifier -n iris-classifier

# Rollback to previous release
helm rollback iris-classifier -n iris-classifier

# Rollback to specific revision
helm rollback iris-classifier 2 -n iris-classifier

# Verify rollback
helm status iris-classifier -n iris-classifier
```

#### 5. **Emergency Rollback** (Scale Down)
**When to use:** Critical issues, need immediate action

**Rollback command:**
```bash
# Scale down to 0 (stop all traffic)
kubectl scale deployment iris-classifier --replicas=0 -n iris-classifier

# Verify scaled down
kubectl get deployment iris-classifier -n iris-classifier

# Scale back up when ready
kubectl scale deployment iris-classifier --replicas=3 -n iris-classifier
```

### Rollback Decision Tree

```
Issue detected?
â”œâ”€ Deployment failed?
â”‚  â””â”€ Use: Rolling Update Rollback
â”‚     kubectl rollout undo deployment/iris-classifier
â”‚
â”œâ”€ Bad canary metrics?
â”‚  â””â”€ Use: Canary Rollback
â”‚     kubectl delete deployment iris-classifier-canary
â”‚
â”œâ”€ Green deployment broken?
â”‚  â””â”€ Use: Blue-Green Rollback
â”‚     kubectl patch service iris-classifier -p '{"spec":{"selector":{"version":"blue"}}}'
â”‚
â”œâ”€ Critical production issue?
â”‚  â””â”€ Use: Emergency Rollback
â”‚     kubectl scale deployment iris-classifier --replicas=0
â”‚
â””â”€ Using Helm?
   â””â”€ Use: Helm Rollback
      helm rollback iris-classifier
```

### Monitoring During Rollback

**Watch rollback progress:**
```bash
# Terminal 1: Watch pods
kubectl get pods -n iris-classifier -w

# Terminal 2: Watch events
kubectl get events -n iris-classifier --sort-by='.lastTimestamp'

# Terminal 3: Monitor metrics
watch -n 1 'curl -s http://localhost:9090/api/v1/query?query=iris_requests_total | jq'
```

**Check metrics after rollback:**
```bash
# Error rate should decrease
curl 'http://localhost:9090/api/v1/query?query=rate(iris_errors_total[5m])'

# Latency should normalize
curl 'http://localhost:9090/api/v1/query?query=histogram_quantile(0.95,iris_request_latency_seconds_bucket)'

# RPS should stabilize
curl 'http://localhost:9090/api/v1/query?query=iris_rps'
```

### Post-Rollback Verification

```bash
# 1. Check pod status
kubectl get pods -n iris-classifier

# 2. Check service endpoints
kubectl get endpoints iris-classifier -n iris-classifier

# 3. Test API
curl http://iris-classifier.example.com/healthz
curl -X POST http://iris-classifier.example.com/predict \
  -H "Content-Type: application/json" \
  -d '{"features": [5.1, 3.5, 1.4, 0.2]}'

# 4. Check logs
kubectl logs -n iris-classifier -l app=iris-classifier --tail=50

# 5. Verify metrics
curl http://localhost:9090/api/v1/query?query=iris_model_loaded
```

**For detailed rollback procedures, see:** `K8S_ROLLBACK_GUIDE.md`

---

## ðŸ“š Documentation

- **MODEL_CARD.md** - Model details, performance, limitations
- **K8s/K8S_SUMMARY.md** - Kubernetes architecture overview
- **K8s/K8S_DEPLOYMENT_STRATEGIES_EXPLAINED.md** - Deployment strategies
- **K8s/K8S_ROLLBACK_GUIDE.md** - Detailed rollback procedures
- **K8s/K8S_ROLLBACK_COMMANDS.md** - 50+ copy-paste commands
- **K8s/K8S_ROLLBACK_CHEATSHEET.md** - Quick reference

## ðŸ§ª Testing

**Run all tests:**
```bash
pytest tests/ -v
```

**Run specific test:**
```bash
pytest tests/test_api.py::test_predict -v
```

**Run with coverage:**
```bash
pytest tests/ --cov=app --cov=train --cov-report=html
```

**Test results:** 23/23 passing âœ…

## ðŸ“¦ Dependencies

**Core:**
- fastapi==0.104.1
- uvicorn==0.24.0
- mlflow==3.6.0
- scikit-learn==1.3.2
- pydantic==2.5.0

**Monitoring:**
- prometheus-client==0.19.0

**Testing:**
- pytest==7.4.3
- pytest-cov==4.1.0

**See:** `requirements.txt` for complete list

## âœ… Minimal Success Path - Status

| Requirement | Status | Details |
|---|---|---|
| FastAPI + 2+ Replicas + Ingress | âœ… COMPLETE | 3 replicas, NGINX, TLS/SSL, round-robin |
| Pipeline: fetchâ†’trainâ†’register | âœ… COMPLETE | MLflow, 3 models, Production stage |
| GitHub Actions CI/CD | âœ… COMPLETE | CI + Auto dev + Manual prod canary |
| Prometheus + Grafana + Alerts | âœ… COMPLETE | 9 metrics, 2 dashboards, 6 alerts |
| Rollout/Rollback Documentation | âœ… COMPLETE | 5 strategies, 50+ commands |
| PostgreSQL Prediction Logging | âœ… COMPLETE | Request tracking, latency logging, /logs endpoint |
| Model Loading (Fixed) | âœ… COMPLETE | Train inside container, correct artifact paths |

## ï¿½ Next Steps

1. **Start Local Stack** - `docker-compose up -d`
2. **Run Training** - `docker exec iris-classifier-api python /app/train/main_loop_models.py`
3. **Test Endpoints** - Use curl or Swagger UI (see API Endpoints section)
4. **View Prediction Logs** - `curl http://localhost:8000/logs`
5. **Deploy to Kubernetes** - `kubectl apply -f k8s/`
6. **Configure Monitoring** - Set up Prometheus scraping
7. **Setup Alerts** - Configure Slack/Email notifications
8. **Monitor Metrics** - Check Grafana dashboards
9. **Practice Rollback** - Test rollback procedures

## ðŸ“„ License

This project is provided as-is for educational and demonstration purposes.

---

**Status**: âœ… Production Ready
**Last Updated**: 2025-11-13
**Version**: 2.1
**Tests**: 23/23 Passing
**Coverage**: 33%

## ðŸŽ‰ Recent Updates (v2.1)

- âœ… **PostgreSQL Prediction Logging** - All predictions logged with request_id, model_version, latency_ms, timestamp
- âœ… **Fixed Model Loading** - Train models inside Docker container to ensure correct artifact paths
- âœ… **New /logs Endpoint** - Retrieve prediction history from PostgreSQL
- âœ… **Fresh Start** - Clean environment with proper path resolution
- âœ… **Database Integration** - PostgreSQL service in docker-compose.yml with health checks

